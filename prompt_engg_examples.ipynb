{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering Techniques\n",
        "By Nilesh Joshi\n",
        "\n",
        "Reference: https://www.promptingguide.ai/techniques \n",
        "\n",
        "\n",
        "This notebook contains examples demonstrating different prompt engineering techniques.\n",
        "\n",
        "- Zero shot\n",
        "- Few shot\n",
        "- CoT\n",
        "- Self Consistency\n",
        "- Generate knowledge prompting\n",
        "- Prompt chaining\n",
        "- Tree of thoughts\n",
        "- RAG\n",
        "- Automatic reasoning and tool use\n",
        "- Automatic prompt engineer\n",
        "- Active-prompt\n",
        "- Directional Stimulus prompting\n",
        "- Program aided language models\n",
        "- ReAct\n",
        "- Multimodal CoT\n",
        "- Graph Prompting"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#checking current dir\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "cwd"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/aoai-poc-vm1/code/Users/nileshjoshi/AOAI-POC'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709947925849
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my virtual environment, I have already installed libraries, below commands to get details of libraries installed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show openai"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: openai\r\nVersion: 1.10.0\r\nSummary: The official Python library for the openai API\r\nHome-page: \r\nAuthor: \r\nAuthor-email: OpenAI <support@openai.com>\r\nLicense: \r\nLocation: /anaconda/envs/condaAoai/lib/python3.11/site-packages\r\nRequires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip freeze"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "aiohttp==3.9.3\r\naiosignal==1.3.1\r\nannotated-types==0.6.0\r\nanyio==4.2.0\r\nasttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\r\nattrs==23.2.0\r\nazure-ai-ml==1.13.0\r\nazure-common==1.1.28\r\nazure-core==1.29.7\r\nazure-identity==1.15.0\r\nazure-mgmt-core==1.4.0\r\nazure-storage-blob==12.19.0\r\nazure-storage-file-datalake==12.14.0\r\nazure-storage-file-share==12.15.0\r\ncachetools==5.3.2\r\ncertifi==2023.11.17\r\ncffi==1.16.0\r\ncharset-normalizer==3.3.2\r\ncolorama==0.4.6\r\ncomm @ file:///work/ci_py311/comm_1677709131612/work\r\ncryptography==42.0.2\r\ndataclasses-json==0.6.4\r\ndebugpy @ file:///croot/debugpy_1690905042057/work\r\ndecorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\r\ndistro==1.9.0\r\nexecuting @ file:///opt/conda/conda-bld/executing_1646925071911/work\r\nfrozenlist==1.4.1\r\ngoogle-api-core==2.16.1\r\ngoogle-auth==2.27.0\r\ngoogleapis-common-protos==1.62.0\r\ngreenlet==3.0.3\r\nh11==0.14.0\r\nhttpcore==1.0.2\r\nhttpx==0.26.0\r\nidna==3.6\r\nipykernel @ file:///croot/ipykernel_1705933831282/work\r\nipython @ file:///croot/ipython_1704833016303/work\r\nisodate==0.6.1\r\njedi @ file:///work/ci_py311_2/jedi_1679336495545/work\r\njsonpatch==1.33\r\njsonpointer==2.4\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\njupyter_client @ file:///croot/jupyter_client_1699455897726/work\r\njupyter_core @ file:///croot/jupyter_core_1698937308754/work\r\nlangchain==0.1.9\r\nlangchain-community==0.0.24\r\nlangchain-core==0.1.27\r\nlangsmith==0.1.10\r\nmarshmallow==3.20.2\r\nmatplotlib-inline @ file:///work/ci_py311/matplotlib-inline_1676823841154/work\r\nmsal==1.26.0\r\nmsal-extensions==1.1.0\r\nmsrest==0.7.1\r\nmultidict==6.0.5\r\nmypy-extensions==1.0.0\r\nnest-asyncio @ file:///work/ci_py311/nest-asyncio_1676823382924/work\r\nnumpy==1.26.3\r\noauthlib==3.2.2\r\nopenai==1.10.0\r\nopencensus==0.11.4\r\nopencensus-context==0.1.3\r\nopencensus-ext-azure==1.1.13\r\norjson==3.9.15\r\npackaging==23.2\r\npandas==2.2.0\r\nparso @ file:///opt/conda/conda-bld/parso_1641458642106/work\r\npexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\r\nplatformdirs @ file:///croot/platformdirs_1692205439124/work\r\nportalocker==2.8.2\r\nprompt-toolkit @ file:///croot/prompt-toolkit_1704404351921/work\r\nprotobuf==4.25.2\r\npsutil @ file:///work/ci_py311_2/psutil_1679337388738/work\r\nptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\r\npyasn1==0.5.1\r\npyasn1-modules==0.3.0\r\npycparser==2.21\r\npydantic==2.6.0\r\npydantic_core==2.16.1\r\npydash==7.0.5\r\nPygments @ file:///croot/pygments_1684279966437/work\r\nPyJWT==2.8.0\r\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\r\npython-dotenv==1.0.1\r\npytz==2023.4\r\nPyYAML==6.0.1\r\npyzmq @ file:///croot/pyzmq_1705605076900/work\r\nreferencing==0.33.0\r\nrequests==2.31.0\r\nrequests-oauthlib==1.3.1\r\nrpds-py==0.17.1\r\nrsa==4.9\r\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\r\nsniffio==1.3.0\r\nSQLAlchemy==2.0.27\r\nstack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\r\nstrictyaml==1.7.3\r\ntenacity==8.2.3\r\ntornado @ file:///croot/tornado_1696936946304/work\r\ntqdm==4.66.1\r\ntraitlets @ file:///work/ci_py311/traitlets_1676823305040/work\r\ntyping-inspect==0.9.0\r\ntyping_extensions==4.9.0\r\ntzdata==2023.4\r\nurllib3==2.2.0\r\nwcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\r\nyarl==1.9.4\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries \n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "import os\n",
        "import IPython\n",
        "from langchain.llms import OpenAI\n",
        "from dotenv import load_dotenv"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1709947930484
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load environment variables from env file. \n",
        "load_dotenv(\"credentials.env\", override=True)\n",
        "\n",
        "# API configuration\n",
        "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "MODEL_DEPLOYMENT_NAME = \"gpt-35-turbo\"\n",
        "# set variables required for LangChain\n",
        "os.environ[\"OPENAI_API_TYPE\"]=os.environ[\"OPENAI_API_TYPE\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_BASE\"]= os.environ[\"AZURE_OPENAI_ENDPOINT\"] # Your Azure OpenAI resource endpoint\n",
        "os.environ[\"OPENAI_API_KEY\"]= os.environ[\"AZURE_OPENAI_API_KEY\"] # Your Azure OpenAI resource key"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1709947930681
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set_openAI_params method - to set parameters for Open AI model\n",
        "#Default:  'temperature=0.7' and 'top-p=1'\n",
        "\n",
        "def set_openAI_params(\n",
        "    model=MODEL_DEPLOYMENT_NAME,\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\" set openai parameters\"\"\"\n",
        "\n",
        "    openai_params = {}    \n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "#completion method : To call AOAI API\n",
        "def get_completion(params, messages):\n",
        "    \"\"\" GET completion from openai api\"\"\"\n",
        "    client = AzureOpenAI(\n",
        "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
        "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "        api_version=\"2023-12-01-preview\" #Function calling works in this API\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_DEPLOYMENT_NAME,\n",
        "        messages=messages,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty']\n",
        "    )    \n",
        "    return response"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1709947930854
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Basic prompt example:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# basic example\n",
        "params = set_openAI_params()\n",
        "\n",
        "prompt = \"The sky is\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1709947931059
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "' blue with fluffy white clouds.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1709947931248
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Try with different temperature to compare results:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_openAI_params(temperature=0)\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": " blue and clear, with a few fluffy white clouds scattered across the horizon. The sun is shining brightly, casting a warm glow over everything below."
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1709947931686
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temperature**: Controls randomness. Lowering the temperature means that the model produces more repetitive and deterministic responses. Increasing the temperature results in more unexpected or creative responses. Try adjusting temperature or Top P but not both.\n",
        "\n",
        "**Top probabilities:** Similar to temperature, this controls randomness but uses a different method. Lowering Top P narrows the model’s token selection to likelier tokens. Increasing Top P lets the model choose from tokens with both high and low likelihood. Try adjusting temperature or Top P but not both.\n",
        "\n",
        "Reference for more details: https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython&pivots=programming-language-studio#settings\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1.1 Text Summarization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_openAI_params(temperature=0.7)\n",
        "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
        "\n",
        "Explain the above in one sentence:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Antibiotics are medications used to treat bacterial infections by either killing the bacteria or preventing their reproduction, but they are not effective against viral infections and misuse can lead to antibiotic resistance."
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1709947932372
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_openAI_params(temperature=0.7)\n",
        "prompt = \"\"\" I am 5. \n",
        "Explain the above in one sentence:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "The speaker is stating their age as 5 years old."
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709947938695
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1.2 Question Answering"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
        "\n",
        "Question: What was OKT3 originally sourced from?\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Mice\n\nUnsure about answer"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1709948022497
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1.3 Text Classification"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "Text: I think the food was okay.\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Neutral"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1709948049717
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Below is modification to same prompt to instruct the model to provide an explanation to the answer selected. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "Text: I think the food was okay.\n",
        "\n",
        "Provide sentiment and explaination about the same in details\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Sentiment: Neutral\n\nExplanation: The statement \"I think the food was okay\" reflects a neutral sentiment as the speaker is not expressing strong positive or negative feelings about the food. They may have found it to be satisfactory but not exceptional. Overall, the sentiment is neutral as it does not convey strong emotions in either direction."
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709948111100
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1.4 Role Playing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
        "\n",
        "Human: Hello, who are you?\n",
        "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
        "Human: Can you tell me about the creation of blackholes?\n",
        "AI:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Certainly. Black holes are formed when massive stars collapse under their own gravity at the end of their life cycle. This collapse causes the star to become extremely dense, with a gravitational pull so strong that even light cannot escape from it. This creates a region of spacetime from which no particles or radiation can escape, known as the event horizon. This phenomenon is what we observe as a black hole."
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1709948473804
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Role Playing example of using Open AI model as customer support agent. Provide necessary instructions about personality of the AI support agent"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are an Xbox customer support agent whose primary goal is to help users with issues they are experiencing with their Xbox devices.\n",
        "You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Xbox.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"How do I perform factory reset? \"\n",
        "    }\n",
        "\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Performing a factory reset on a device can vary depending on the specific make and model. Here are general steps to perform a factory reset on most devices:\n\n1. Back up your important data: Before performing a factory reset, make sure to back up any important data, such as photos, videos, contacts, and documents to ensure you don't lose them.\n\n2. Access the settings: Go to the \"Settings\" or \"System\" menu on your device.\n\n3. Find the reset option: Look for an option like \"Backup & reset,\" \"Reset,\" or \"Factory data reset\" within the settings menu.\n\n4. Initiate the reset: Select the option to perform a factory reset and confirm your decision when prompted. You may need to enter your device's PIN or passcode to proceed.\n\n5. Wait for the process to complete: The device will then begin the factory reset process, which may take a few minutes to complete.\n\n6. Set up your device: Once the factory reset is complete, you will need to set up your device as if it were new, including connecting to Wi-Fi, signing in to your accounts, and restoring your backed-up data.\n\nRemember that performing a factory reset will erase all data on the device, so be sure to back up"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709948523881
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1.5 Code Generation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "SELECT s.StudentId, s.StudentName\nFROM students s\nJOIN departments d ON s.DepartmentId = d.DepartmentId\nWHERE d.DepartmentName = 'Computer Science';"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1709078472549
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1.6 Reasoning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
        "\n",
        "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "The odd numbers in the group are 15, 5, 13, 7, and 1.\n\nAdding them together:\n15 + 5 + 13 + 7 + 1 = 41\n\nThe result, 41, is an odd number."
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1709078490501
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Exercise: Improve the prompt to have a better structure and output format."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## 2. Advanced Prompting Techniques\n",
        "\n",
        "Objectives:\n",
        "\n",
        "- Cover more advanced techniques for prompting: few-shot, chain-of-thoughts,..."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 2.2 Few-shot prompts"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
        "A: The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
        "A: The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
        "A: The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
        "A:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "The answer is False."
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1709078503722
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 2.3 Chain-of-Thought (CoT) Prompting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
        "A:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False."
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1709078520358
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 2.4 Zero-shot CoT"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
        "\n",
        "Let's think step by step.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "You started with 10 apples. Then you gave away 2 + 2 = 4 apples. \n\nSo, you had 10 - 4 = 6 apples left. \n\nAfter that, you bought 5 more apples, so you had 6 + 5 = 11 apples. \n\nThen you ate 1, so you remained with 11 - 1 = 10 apples. \n\nSo, you remained with 10 apples in total."
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1709078533588
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 2.5 Self-Consistency\n",
        "As an exercise, check examples in our [guide](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-advanced-usage.md#self-consistency) and try them here. \n"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"When I was 6 my sister was half my age.Now, I am 70 how old is my sister?\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Your sister is 68 years old."
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709078877319
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "above answer is wrong, in such scenarios we need to use CoT with Fewshots (aka Self consistency). See below"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
        "there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
        "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
        "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
        "did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
        "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
        "he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
        "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
        "monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
        "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
        "The answer is 29.\n",
        "\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
        "golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
        "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent 5\n",
        "\n",
        "Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?\n",
        "A:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "When you were 6, your sister was half your age, so she was 3 years old. Now that you are 70, your sister is 70 - (6-3) = 67 years old."
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709078971743
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 Generate Knowledge Prompting\n",
        "\n",
        "As an exercise, check examples in our [guide](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-advanced-usage.md#generated-knowledge-prompting) and try them here. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Part of golf is trying to get a higher point total than others. Yes or No?\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Yes."
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709079066059
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This type of mistake reveals the limitations of LLMs to perform tasks that require more knowledge about the world. How do we improve this with knowledge generation?\n",
        "\n",
        "First, we generate a few \"knowledges\""
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Question: Part of golf is trying to get a higher point total than others. Yes or No?\n",
        "\n",
        "Knowledge: The objective of golf is to play a set of holes in the least number of strokes. A round of golf typically consists of 18 holes. Each hole is played once in the round on a standard golf course. Each stroke is counted as one point, and the total number of strokes is used to determine the winner of the game.\n",
        "\n",
        "Explain and Answer: \"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "No, the objective of golf is not to get a higher point total than others. In fact, the objective of golf is to play a set of holes in the least number of strokes. Each stroke is counted as one point, and the total number of strokes is used to determine the winner of the game. Therefore, the goal is to have the lowest point total, not the highest."
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709079128951
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus above approach of feeding knowledge works better in such scenarios."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.7 Prompt Chaining\n",
        "\n",
        "https://www.promptingguide.ai/techniques/prompt_chaining"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a helpful assistant. Your task is to help answer a question given a document.The first step is to extract quotes relevant to the question from the document, delimited by ####. Please output the list of quotes using <quotes></quotes>. Respond with \"No relevant quotes found!\" if no relevant quotes were found.\n",
        "####Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics. Prompt engineering skills help to better understand the capabilities and limitations of large language models (LLMs).\n",
        "Below are some of the prompt engineering techniques:\n",
        "#### Chain-of-thought (CoT) prompting ####\n",
        "#### Generated knowledge prompting #### \n",
        "#### Least-to-most prompting #### Self-consistency decoding #### Complexity-based prompting #### Self-refine #### Tree-of-thought prompting#### Maieutic prompting #### Directional-stimulus prompting #### Textual inversion and embeddings #### Using gradient descent to search for prompts #### Prompt injection ####\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "<quotes>Chain-of-thought (CoT) prompting</quotes>\n<quotes>Least-to-most prompting</quotes>\n<quotes>Self-consistency decoding</quotes>\n<quotes>Complexity-based prompting</quotes>\n<quotes>Tree-of-thought prompting</quotes>\n<quotes>Directional-stimulus prompting</quotes>\n<quotes>Textual inversion and embeddings</quotes>\n<quotes>Using gradient descent to search for prompts</quotes>\n<quotes>Prompt injection</quotes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709080031864
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt chaining\n",
        "Tree of thought\n",
        "RAG\n",
        "Automatic reasoning and tool use\n",
        "Automatic prompt engineer\n",
        "Active prompt\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "aoaikernel2",
      "language": "python",
      "display_name": "aoaikernel2"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f38e0373277d6f71ee44ee8fea5f1d408ad6999fda15d538a69a99a1665a839d"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "aoaikernel2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}